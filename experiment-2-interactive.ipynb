{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# Experiment 2: Interactive reprocessing\n",
    "This is representative of a new type of functionality that we currently don’t support in METASPACE\n",
    "because it’s uneconomical with the serverful approach. While looking for specific compounds,\n",
    "scientists tend to have relatively short lists of molecules of interest, and iteratively try\n",
    "different adducts or modifiers until they find the data they’re interested in.\n",
    "\n",
    "### METRICS TO BENCHMARK\n",
    "* Performance:\n",
    "    * **Metric:** Total processing time\n",
    "    \n",
    "        **Goal:** Fast enough to use interactively in a notebook - less than ~60 seconds\n",
    "\n",
    "* Cost:\n",
    "    * **Metric:** Total cost\n",
    "    \n",
    "        **Goal:** Significantly less than a full annotation - determined by experiment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook setup\n",
    "Run `python3 setup.py install` to install all requirements for annotation pipeline project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We need this to overcome Python notebooks limitations of too many open files\n",
    "import resource\n",
    "soft, hard = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "print('Before:', soft, hard)\n",
    "\n",
    "# Raising the soft limit. Hard limits can be raised only by sudo users\n",
    "resource.setrlimit(resource.RLIMIT_NOFILE, (10000, hard))\n",
    "soft, hard = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "print('After:', soft, hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# If pywren_ibm_cloud isn't installed, please run `pip install -e .` in this directory to install all dependencies\n",
    "import pywren_ibm_cloud as pywren\n",
    "\n",
    "pywren.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a socket timeout so that CF requests fail instead of hanging if they don't get a response\n",
    "import socket\n",
    "print('Previous timeout:', socket.getdefaulttimeout())\n",
    "socket.setdefaulttimeout(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "config = json.load(open('config.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#input_config = json.load(open('metabolomics/input_config_small.json'))\n",
    "input_config = json.load(open('metabolomics/input_config_big.json'))\n",
    "#input_config = json.load(open('metabolomics/input_config_huge.json'))\n",
    "input_data = input_config['dataset']\n",
    "input_db = input_config['molecular_db']\n",
    "\n",
    "# Override databases, because this experiment expects a small database\n",
    "exp_db_path = 'metabolomics/db/mol_db5.pickle'\n",
    "input_db['databases'] = [exp_db_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check input dataset is present\n",
    "from annotation_pipeline.utils import ds_imzml_path\n",
    "import sys\n",
    "try:\n",
    "    assert ds_imzml_path(input_config['dataset']['path'])\n",
    "except:\n",
    "    print(f\"No imzML file was found in {input_config['dataset']['path']}. \"\n",
    "           \"Please follow the instructions in README.md to download and extract the dataset required by this input_config.json file.\",\n",
    "          file=sys.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial setup (not included in benchmark timings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annotation_pipeline.molecular_db import build_database, calculate_centroids, get_formula_id_dfs\n",
    "from annotation_pipeline.pipeline import Pipeline\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load & segment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(config, input_config)\n",
    "pipeline.load_ds()\n",
    "pipeline.split_ds()\n",
    "pipeline.segment_ds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annotation_pipeline.utils import get_ibm_cos_client\n",
    "cos_client = get_ibm_cos_client(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annotation_pipeline.utils import init_pywren_stats\n",
    "init_pywren_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process new molecules and Run Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "# Process new molecules:\n",
    "## Upload list of molecules (in a real scenario this list would change every iteration, so this isn't part of setup)\n",
    "mols = pd.read_csv('metabolomics/db/mol_db5.csv')\n",
    "mols_list = sorted(set(mols.sf.values.tolist()))\n",
    "cos_client.put_object(Bucket=config['storage']['db_bucket'], Key=exp_db_path, Body=pickle.dumps(mols_list))\n",
    "build_database(config, input_db)\n",
    "polarity = input_data['polarity']\n",
    "isocalc_sigma = input_data['isocalc_sigma']\n",
    "calculate_centroids(config, input_db, polarity, isocalc_sigma)\n",
    "pipeline.segment_centroids()\n",
    "\n",
    "# Run Annotation:\n",
    "pipeline.annotate()\n",
    "results_df = pipeline.formula_metrics_df\n",
    "\n",
    "finish_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('start', start_time)\n",
    "print('finish', finish_time)\n",
    "print('duration', finish_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display PyWren statistics file\n",
    "from annotation_pipeline.utils import get_pywren_stats\n",
    "get_pywren_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annotation_pipeline.utils import remove_pywren_stats\n",
    "remove_pywren_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "print(results_df.shape)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Temp Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annotation_pipeline.utils import clean_from_cos\n",
    "clean_from_cos(config, config[\"storage\"][\"ds_bucket\"], \"metabolomics/tmp\")\n",
    "clean_from_cos(config, config[\"storage\"][\"db_bucket\"], \"metabolomics/tmp\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
