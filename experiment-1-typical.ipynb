{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# Experiment 1: Typical use case\n",
    "This is representative of a normal use-case on METASPACE, which makes it suitable for head-to-head comparisons. There is often limited time available on the higher-spec PC used for initial data capture as it is a shared resource, so usually the analysis will be performed from scientists’ or students’ lower-spec laptops.\n",
    "\n",
    "### METRICS TO BENCHMARK\n",
    "* Performance:\n",
    "    * **Metric:** Total processing time up to downloading the results dataframe\n",
    "    \n",
    "        **Goal:** Faster than serverful METASPACE (including or excluding cluster start time)\n",
    "\n",
    "    * **Metric:** Latency for retrieving all images of target ions.\n",
    "    \n",
    "        **Goal:** Similar to or faster than METASPACE’s python client\n",
    "\n",
    "* Capability:\n",
    "    * **Metric:** Peak memory usage on client.\n",
    "    \n",
    "        **Goal:** Capable of running on low-spec PC with 8GB ram, so ~6GB max usage\n",
    "\n",
    "* Cost:\n",
    "    * **Metric:** Cloud provider cost\n",
    "    \n",
    "        **Goal:** Similar price or cheaper than METASPACE (including or excluding cluster start time)\n",
    "\n",
    "    * **Metric:** Developer time\n",
    "    \n",
    "        **Goal:** Less annual time required to manage cloud infrastructure than METASPACE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook setup\n",
    "Run `python3 setup.py install` to install all requirements for annotation pipeline project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We need this to overcome Python notebooks limitations of too many open files\n",
    "import resource\n",
    "soft, hard = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "print('Before:', soft, hard)\n",
    "\n",
    "# Raising the soft limit. Hard limits can be raised only by sudo users\n",
    "resource.setrlimit(resource.RLIMIT_NOFILE, (10000, hard))\n",
    "soft, hard = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "print('After:', soft, hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# These are Python and Python lib path we want to use\n",
    "import sys\n",
    "sys.executable, sys.prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Install PyWren-IBM if needed\n",
    "try:\n",
    "    import pywren_ibm_cloud as pywren\n",
    "except ModuleNotFoundError:    \n",
    "    !{sys.executable} -m pip install -U pywren-ibm-cloud==1.0.10\n",
    "    import pywren_ibm_cloud as pywren\n",
    "\n",
    "pywren.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install psutil if needed\n",
    "try:\n",
    "    import psutil\n",
    "except ModuleNotFoundError:    \n",
    "    !{sys.executable} -m pip install -U psutil\n",
    "    import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "config = json.load(open('config.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#input_config = json.load(open('metabolomics/input_config_small.json'))\n",
    "input_config = json.load(open('metabolomics/input_config_big.json'))\n",
    "#input_config = json.load(open('metabolomics/input_config_huge.json'))\n",
    "input_data = input_config['dataset']\n",
    "input_db = input_config['molecular_db']\n",
    "\n",
    "# Override config to match METASPACE annotation settings\n",
    "input_data['num_decoys'] = 20\n",
    "input_db['modifiers'] = ['']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup (Not included in benchmark timings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from annotation_pipeline.molecular_db import dump_mol_db, build_database, \\\n",
    "    calculate_centroids, get_formula_id_dfs, clean_formula_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Download commonly used mol DBs from METASPACE (add force=True to redownload if needed)\n",
    "dump_mol_db(config, config['storage']['db_bucket'], 'metabolomics/db/mol_db1.pickle', 22) #HMDB-v4\n",
    "dump_mol_db(config, config['storage']['db_bucket'], 'metabolomics/db/mol_db2.pickle', 19) #ChEBI-2018-01\n",
    "dump_mol_db(config, config['storage']['db_bucket'], 'metabolomics/db/mol_db3.pickle', 24) #LipidMaps-2017-12-12\n",
    "dump_mol_db(config, config['storage']['db_bucket'], 'metabolomics/db/mol_db4.pickle', 26) #SwissLipids-2018-02-02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_formulas, formula_chunk_keys = build_database(config, input_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "polarity = input_data['polarity']\n",
    "isocalc_sigma = input_data['isocalc_sigma']\n",
    "centroids_shape, centroids_head = calculate_centroids(config, input_db, formula_chunk_keys, polarity, isocalc_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clean_formula_chunks(config, input_db, formula_chunk_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psutil # \"pip install psutil\" if needed\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "memory_usage_mb = psutil.Process(os.getpid()).memory_info().rss / 2**20\n",
    "print(f'Memory usage before: {memory_usage_mb:.0f}MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annotation_pipeline.utils import init_pywren_stats\n",
    "init_pywren_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "### Run Annotation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from annotation_pipeline.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(config, input_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "pipeline()\n",
    "results_df = pipeline.get_results()\n",
    "finish_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('start', start_time)\n",
    "print('finish', finish_time)\n",
    "print('duration', finish_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display PyWren statistics file\n",
    "pd.read_csv('stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annotation_pipeline.utils import remove_pywren_stats\n",
    "remove_pywren_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_usage_mb = psutil.Process(os.getpid()).memory_info().rss / 2**20\n",
    "print(f'Memory usage after: {memory_usage_mb:.0f}MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark Part 2\n",
    "Comparing the time required to retrieve all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install metaspace2020 if needed (May require kernel restart)\n",
    "try:\n",
    "    from metaspace.sm_annotation_utils import SMInstance\n",
    "except ModuleNotFoundError:    \n",
    "    !{sys.executable} -m pip install -U metaspace2020\n",
    "    from metaspace.sm_annotation_utils import SMInstance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time images_dict = pipeline.get_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMInstance()\n",
    "# TODO: (EMBL) Reprocess these datasets with the other DBs, because currently they only have HMDB-v4\n",
    "ds = sm.dataset(id='2016-09-22_11h16m11s') # For input_config_small.json\n",
    "#ds = sm.dataset(id='2016-09-21_16h06m52s') # For input_config_big.json\n",
    "#ds = sm.dataset(id='2016-09-21_16h06m49s') # For input_config_huge.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time metaspace_client_images = ds.all_annotation_images(fdr=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check results are correct (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[lambda df: (df.mol == 'C42H84NO8P') & (df.adduct == '+H')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_results = ds.results()\n",
    "reference_results = reference_results.rename({'moc':'chaos', 'rhoSpatial': 'spatial', 'rhoSpectral': 'spectral'}, axis=1)\n",
    "reference_results = reference_results[['chaos', 'spatial', 'spectral', 'msm', 'fdr']]\n",
    "reference_results = reference_results.reset_index()\n",
    "\n",
    "filtered_results = results_df\n",
    "filtered_results = filtered_results[filtered_results.database_path == 'metabolomics/db/mol_db1.pickle']\n",
    "#filtered_results = filtered_results[filtered_results.fdr <= 0.5]\n",
    "filtered_results = filtered_results[filtered_results.adduct != '']\n",
    "filtered_results = filtered_results[filtered_results.modifier == '']\n",
    "filtered_results = filtered_results.rename({'mol': 'formula'}, axis=1)\n",
    "filtered_results = filtered_results[['chaos', 'spatial', 'spectral', 'msm', 'fdr', 'formula', 'adduct', 'modifier']]\n",
    "\n",
    "merged_results = reference_results.merge(filtered_results, how='outer', left_on=['formula','adduct'], right_on=['formula','adduct'], suffixes=['_ref',''])\n",
    "merged_results = merged_results.sort_values(['formula','adduct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_results[['spatial', 'spatial_ref']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_results = merged_results[merged_results.fdr.notna() & merged_results.fdr_ref.notna()]\n",
    "spatial_wrong = common_results[np.abs((common_results.spatial - common_results.spatial_ref)) >= 0.01]\n",
    "assert len(spatial_wrong) < 5, spatial_wrong # Higher tolerance because older DSs seem to have used a different algorithm\n",
    "spectral_wrong = common_results[np.abs((common_results.spectral - common_results.spectral_ref)) >= 0.001]\n",
    "assert len(spectral_wrong) <= 1, spectral_wrong\n",
    "chaos_wrong = common_results[np.abs((common_results.chaos - common_results.chaos_ref)) >= 0.01]\n",
    "assert len(chaos_wrong) <= 1, chaos_wrong\n",
    "msm_wrong = common_results[np.abs((common_results.msm - common_results.msm_ref)) >= 0.001]\n",
    "assert len(msm_wrong) <= 10, msm_wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def quantize_fdr(fdr):\n",
    "    if fdr <= 0.05: return 1\n",
    "    if fdr <= 0.1: return 2\n",
    "    if fdr <= 0.2: return 3\n",
    "    if fdr <= 0.5: return 4\n",
    "    return 5\n",
    "    \n",
    "fdr_level = merged_results.fdr.apply(quantize_fdr)\n",
    "fdr_ref_level = merged_results.fdr_ref.apply(quantize_fdr)\n",
    "\n",
    "fdr_exact = merged_results[fdr_level == fdr_ref_level]\n",
    "fdr_near = merged_results[np.abs(fdr_level - fdr_ref_level) <= 1]\n",
    "print(len(fdr_exact), len(fdr_near), len(merged_results))\n",
    "assert len(fdr_exact) >= len(merged_results) * 0.5\n",
    "assert len(fdr_near) >= len(merged_results) * 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Temp Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annotation_pipeline.utils import clean_from_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean dataset chunks\n",
    "clean_from_cos(config, config[\"storage\"][\"ds_bucket\"], input_data[\"ds_chunks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean dataset segments\n",
    "clean_from_cos(config, config[\"storage\"][\"ds_bucket\"], input_data[\"ds_segments\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean centroids database segments\n",
    "clean_from_cos(config, config[\"storage\"][\"db_bucket\"], input_db[\"centroids_segments\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean formula output images\n",
    "clean_from_cos(config, config[\"storage\"][\"output_bucket\"], output[\"formula_images\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean FDR rankings\n",
    "clean_from_cos(config, config[\"storage\"][\"ds_bucket\"], input_data[\"fdr_rankings\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
