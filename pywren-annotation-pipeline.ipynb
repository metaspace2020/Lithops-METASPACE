{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metaspace annotation pipeline on IBM Cloud\n",
    "\n",
    "Experimental code to integrate Metaspace [engine](https://github.com/metaspace2020/metaspace/tree/master/metaspace/engine)\n",
    "with [PyWren](https://github.com/pywren/pywren-ibm-cloud) for IBM Cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Setup](#setup)\n",
    "2. [Generate Isotopic Peaks from Molecular Databases](#database)\n",
    "3. [Run Annotation Pipeline](#annotation)\n",
    "4. [Display results](#display)\n",
    "5. [Validate results](#validate)\n",
    "6. [Clean Temp Data in IBM COS](#clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# <a name=\"setup\"></a> 1. Setup\n",
    "\n",
    "This notebook requires IBM Cloud Object Storage and IBM Cloud Functions\n",
    "Please follow IBM Cloud dashboard and create both services.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We need this to overcome Python notebooks limitations of too many open files\n",
    "import resource\n",
    "soft, hard = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "print('Before:', soft, hard)\n",
    "\n",
    "# Raising the soft limit. Hard limits can be raised only by sudo users\n",
    "resource.setrlimit(resource.RLIMIT_NOFILE, (10000, hard))\n",
    "soft, hard = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "print('After:', soft, hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Run this for DEBUG mode\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "### IBM COS Setup\n",
    "\n",
    "Copy the file `config.json.template` to `config.json` and fill in the missing values for API keys, buckets and endpoints per these instructions:\n",
    "\n",
    "Setup a bucket in IBM Cloud Object Storage\n",
    "\n",
    "You need an IBM COS bucket which you will use to store the input data. If you don't know of any of your existing buckets or would like like to create a new one, please navigate to your cloud resource list, then find and select your storage instance. From here, you will be able to view all your buckets and can create a new bucket in the region you prefer. Make sure you copy the correct endpoint for the bucket from the Endpoint tab of this COS service dashboard. Note: The bucket names must be unique.\n",
    "\n",
    "Obtain the API key and endpoint to the IBM Cloud Functions service. Navigate to Getting Started > API Key from the side menu and copy the values for \"Current Namespace\", \"Host\" and \"Key\" into the config below. Make sure to add \"https://\" to the host when adding it as the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "config = json.load(open('config.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from annotation_pipeline.utils import get_ibm_cos_client\n",
    "cos_client = get_ibm_cos_client(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IBM PyWren Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# If pywren_ibm_cloud isn't installed, please run `pip install -e .` in this directory to install all dependencies\n",
    "import pywren_ibm_cloud as pywren\n",
    "\n",
    "pywren.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "### Input Files Setup\n",
    "\n",
    "Choose between the input config files to select how much processing will be done. See the `README.md` for more information on each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "#input_config = json.load(open('metabolomics/input_config_small.json'))\n",
    "input_config = json.load(open('metabolomics/input_config_big.json'))\n",
    "#input_config = json.load(open('metabolomics/input_config_huge.json'))\n",
    "#input_config = json.load(open('metabolomics/input_config_huge2.json'))\n",
    "#input_config = json.load(open('metabolomics/input_config_huge3.json'))\n",
    "input_data = input_config['dataset']\n",
    "input_db = input_config['molecular_db']\n",
    "output = input_config['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please note that some input_configs specify a `mol_db6`, which is not yet publicly available.\n",
    "# This will remove it from the config to prevent later errors. Results will still be generated for other databases.\n",
    "input_db['databases'] = [db for db in input_db['databases'] if 'mol_db6' not in db]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate that dataset is present\n",
    "\n",
    "Download links for example datasets can be found in [README.md](https://github.com/metaspace2020/pywren-annotation-pipeline/blob/master/README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annotation_pipeline.utils import ds_imzml_path\n",
    "import sys\n",
    "try:\n",
    "    assert ds_imzml_path(input_config['dataset']['path'])\n",
    "except:\n",
    "    print(f\"No imzML file was found in {input_config['dataset']['path']}. \"\n",
    "           \"Please follow the instructions in README.md to download and extract the dataset required by this input_config.json file.\",\n",
    "          file=sys.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# <a name=\"database\"></a> 2. Generate Isotopic Peaks from Molecular Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from annotation_pipeline.molecular_db import build_database, calculate_centroids, upload_mol_dbs_from_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Upload databases\n",
    "upload_mol_dbs_from_dir(config, config['storage']['db_bucket'], 'metabolomics/db', 'metabolomics/db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_formulas, num_formulas_chunks = build_database(config, input_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_formulas, num_formulas_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "polarity = input_data['polarity'] # Use '+' if missing from the config, but it's better to get the actual value as it affects the results\n",
    "isocalc_sigma = input_data['isocalc_sigma'] # Use 0.001238 if missing from the config, but it's better to get the actual value as it affects the results\n",
    "num_centroids, num_centroids_chunks = calculate_centroids(config, input_db, polarity, isocalc_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_centroids, num_centroids_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# <a name=\"annotation\"></a> 3. Run Annotation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from annotation_pipeline.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(config, input_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%time pipeline.load_ds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we upload spectra chunks to COS\n",
    "%time pipeline.split_ds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#sort of input dataset\n",
    "%time pipeline.segment_ds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#sort of input databases\n",
    "%time pipeline.segment_centroids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#annotation engine - generate images in COS\n",
    "%time pipeline.annotate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time pipeline.run_fdr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time results_df = pipeline.get_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"display\"></a> 4. Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we download pickled output images from COS\n",
    "%time formula_images = pipeline.get_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_mols = (results_df\n",
    "               .sort_values('msm', ascending=False)\n",
    "               .drop('database_path', axis=1)\n",
    "               .drop_duplicates(['mol','modifier','adduct']))\n",
    "top_mols.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display images\n",
    "import matplotlib.pyplot as plt\n",
    "for i, (formula_i, row) in enumerate(top_mols.head().iterrows()):\n",
    "    plt.figure(i)\n",
    "    plt.title(f'{row.mol}{row.modifier}{row.adduct} - MSM {row.msm:.3f}')\n",
    "    plt.imshow(formula_images[formula_i][0].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"validate\"></a> 5. Validate Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that due to minor changes in the METASPACE algorithm since these datasets were originally uploaded, only the \"big\" dataset currently passes this validation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checked_results = pipeline.check_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# <a name=\"clean\"></a> 6. Clean Temp Data in IBM COS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from annotation_pipeline.utils import clean_from_cos\n",
    "clean_from_cos(config, config[\"storage\"][\"ds_bucket\"], \"metabolomics/tmp\")\n",
    "clean_from_cos(config, config[\"storage\"][\"db_bucket\"], \"metabolomics/tmp\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
