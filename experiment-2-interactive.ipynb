{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# Experiment 2: Interactive reprocessing\n",
    "This is representative of a new type of functionality that we currently don’t support in METASPACE\n",
    "because it’s uneconomical with the serverful approach. While looking for specific compounds,\n",
    "scientists tend to have relatively short lists of molecules of interest, and iteratively try\n",
    "different adducts or modifiers until they find the data they’re interested in.\n",
    "\n",
    "### METRICS TO BENCHMARK\n",
    "* Performance:\n",
    "    * **Metric:** Total processing time\n",
    "    \n",
    "        **Goal:** Fast enough to use interactively in a notebook - less than ~60 seconds\n",
    "\n",
    "* Cost:\n",
    "    * **Metric:** Total cost\n",
    "    \n",
    "        **Goal:** Significantly less than a full annotation - determined by experiment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# These are Python and Python lib path we want to use\n",
    "import sys\n",
    "sys.executable, sys.prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Install PyWren-IBM if needed\n",
    "try:\n",
    "    import pywren_ibm_cloud as pywren\n",
    "except ModuleNotFoundError:    \n",
    "    !{sys.executable} -m pip install -U pywren-ibm-cloud==1.0.10\n",
    "    import pywren_ibm_cloud as pywren\n",
    "\n",
    "pywren.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We need this to overcome Python notebooks limitations of too many open files\n",
    "import resource\n",
    "soft, hard = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "print('Before:', soft, hard)\n",
    "\n",
    "# Raising the soft limit. Hard limits can be raised only by sudo users\n",
    "resource.setrlimit(resource.RLIMIT_NOFILE, (hard, hard))\n",
    "soft, hard = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "print('After:', soft, hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from scipy.sparse import coo_matrix\n",
    "from collections import defaultdict\n",
    "from pyImagingMSpec.image_measures import isotope_image_correlation, isotope_pattern_match\n",
    "from cpyImagingMSpec import measure_of_chaos\n",
    "from itertools import chain\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = json.load(open('config.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# input_config = json.load(open('metabolomics/input_config_small.json'))\n",
    "input_config = json.load(open('metabolomics/input_config_big.json'))\n",
    "# input_config = json.load(open('metabolomics/input_config_huge.json'))\n",
    "input_data = input_config['dataset']\n",
    "input_db = input_config['molecular_db']\n",
    "\n",
    "# Override databases, because this experiment expects a small database\n",
    "exp_db_path = 'metabolomics/db/mol_db5.pickle'\n",
    "input_db['databases'] = [exp_db_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import ibm_boto3\n",
    "from ibm_botocore.client import Config\n",
    "from ibm_botocore.client import ClientError\n",
    "cos_client = ibm_boto3.client(service_name='s3',\n",
    "                              ibm_api_key_id=config['ibm_cos']['api_key'],\n",
    "                              config=Config(signature_version='oauth'),\n",
    "                              endpoint_url=config['ibm_cos']['endpoint'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial setup (not included in benchmark timings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "### Upload test data into COS bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from annotation_pipeline_v2.utils import upload_to_cos\n",
    "for root, dirnames, filenames in os.walk(input_data['path']):\n",
    "    for fn in filenames:\n",
    "        f_path = f'{root}/{fn}'\n",
    "        print(f_path)\n",
    "        upload_to_cos(cos_client, f_path, config['storage']['ds_bucket'], f_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load & segment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annotation_pipeline_v2.pipeline import Pipeline\n",
    "pipeline = Pipeline(config, input_config)\n",
    "pipeline.load_ds()\n",
    "pipeline.segment_ds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "print('start', start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process new molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from annotation_pipeline.molecular_db import build_database, calculate_centroids, get_formula_id_dfs, clean_formula_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload list of molecules (in a real scenario this list would change every iteration, so this isn't part of setup)\n",
    "mols = pd.read_csv('metabolomics/db/mol_db5.csv')\n",
    "mols_list = sorted(set(mols.sf.values.tolist()))\n",
    "cos_client.put_object(Bucket=config['storage']['db_bucket'], Key=exp_db_path, Body=pickle.dumps(mols_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_formulas, formula_chunk_keys = build_database(config, input_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "isocalc_sigma = input_data['isocalc_sigma'] # Use 0.001238 if missing from the config, but it's better to get the actual value as it affects the results\n",
    "centroids_shape, centroids_head = calculate_centroids(config, input_db, formula_chunk_keys, isocalc_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Download centroids.pickle to local machine (Can be removed when pipeline can run directly from COS)\n",
    "resp = cos_client.get_object(Bucket=config['storage']['db_bucket'], Key=input_db['centroids_pandas'])\n",
    "with open(input_db['centroids_pandas'], 'wb') as f:\n",
    "    f.write(resp['Body'].read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clean_formula_chunks(config, input_db, formula_chunk_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time pipeline.segment_centroids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "### Run Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time pipeline.annotate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time results_df = pipeline.formula_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "print(results_df.shape)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finish_time = datetime.now()\n",
    "print('start', start_time)\n",
    "print('finish', finish_time)\n",
    "print('duration', finish_time - start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sm]",
   "language": "python",
   "name": "conda-env-sm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
